# 科学计算引论笔记

## Chapter1 误差

### 一. 误差控制

- 避免大数除小数

  $\frac{x}{y},y\rightarrow0,x$的微小波动会引起很大误差

- 避免相近数相减

  相近数相减会损失有效数字

- 避免大数吃小数

  $Eg:A=5331, B=0.001,A+B$中 $B$就会被忽略(Solution:对数化)

- 减少运算次数

  多次迭代会导致误差被放大

### 二. 有效数字（重要）

​		**定义**：若$x^{*}$的近似值$x=\pm x_1x_2\ldots x_n\times10^m$，其中$x_1\neq0$，诸$x_i\in\{0,1,2,\ldots,9\}$，$m\in\Z$，且
$$
|x-x^*|\leq\frac{1}{2}\times10^{m-p},1\leq p\leq n
$$
则称近似值$x$有$p$位有效数字或称$x$精确到$10^{m-p}$位

$Example:$若以$\displaystyle\frac{355}{113}$作为圆周率$\pi$的逼近值，问此逼近值具有多少位有效数字
解：$\displaystyle x=\frac{325}{113}=0.314159204\ldots\times10^1$
$|x-\pi|=2.6676\ldots\times10^{-7}<0.5\times10^{-6}=0.5\times10^{1-7}$
$\therefore$有7位有效数字

## Chapter2 迭代法

### 一. 二分法

#### 1. 二分法的定义

用分点 $a_{0}\:=\:a,x_{0}\:=\:\frac{1}{2}(a+b),b_{0}\:=\:b$ 将区间 $[a,b]$ 二等分

并计算函数值 $f(x_{0}).$ 若 $f(x_{0})=0,$ 则求得实根 $x^*=x_0;$ 否则$f(x_{0})$与 $f(a)$ 或 $f(b)$ 异号.若 $f(a)f(x_{0})<0,$ 则根在区间 $[a,x_0]$内,取 $a_1=a,b_1=x_0;$ 若 $f(x_0)f(b)<0,$ 则根在区间 $[x_0,b]$ 内,取
$$
a_1=x_0,b_1=b.
$$

不断重复上述二分步骤,则可得系列隔离区间

$$
[a_0,b_0]\supset[a_1,b_1]\supset[a_2,b_2]\supset\cdots\supset[a_k,b_k]\supset\cdots
$$

其中二分$k$次后的隔离区间 $[a_{k},b_{k}]$ 的长度为

$$
b_k-a_k=\frac1{2^k}(b-a).
$$

若记隔离区间 $[a_k,b_k]$ 的中点 $x_{k}=\frac{1}{2}(a_{k}+b_{k}),$ 则有：

$$
\begin{aligned}|x^*-x_k|\leqslant\frac{1}{2}(b_k-a_k)=\frac{1}{2^{k+1}}(b-a),\quad k=0,1,2,\cdots.\end{aligned}
$$

由此可知,随着二分次数 $\text{k}$ 的增加,序列 $\{x_k\}$ 愈来愈逼近精确解 $x^{*}.$ 因此,我们可取序列 $\{x_k\}$ 作为精确解$x^*$的逼近解序列若预定精度要求为 $\varepsilon>0:|x^{*}-x_{k}|<\varepsilon,$ ,我们只需

$$
k>\frac{\ln(b-a)-\ln(2\varepsilon)}{\ln2}.
$$

以上即为二分法的过程

#### 2. 二分法的优缺点

- 计算简单
- 对函数要求很低，仅需连续
- 收敛速度慢
- 未充分利用函数值信息

### 二. 简单迭代

#### 1. Picard迭代法

​	**定理2**：设 Picard迭代格式（2.12)中的迭代函数 $\varphi(x)$ 满足下列条件：
$$
\begin{aligned}
&(1)\forall x\in[a,b],a\leqslant\varphi(x)\leqslant b;\\
&(2)\exist q\in(0,1), s.t.\forall x\in[a,b],|\varphi^{\prime}(x)|\leqslant q<1,
\end{aligned}
$$
​	则该迭代格式自任意初值$x_0\in[a,b]$ 出发均收敛于方程$x=\varphi(x)$的根 $x^*$,且有如下误差估计:
$$
\begin{aligned}
&(a) |x^*-x_k|\leq\frac{1}{1-q}|x_{k+1}-x_{k}|\\
&(b)|x^*-x_k|\leq\frac{q^k}{1-q}|x_{1}-x_{0}|
\end{aligned}
$$
证明：

事实上：我们有$|x_{k+1}-x_k|=|\varphi^\prime(\zeta)||x_{k}-x_{k-1}|\leq q|x_{k}-x_{k-1}|\leq q^2|x_{k-1}-x_{k-2}|\leq\ldots\leq q^{k}|x_1-x_0|$
$$
\begin{aligned}
|x_{n+p}-x_k|&=|x_{n+p}-x_{n+p-1}+x_{n+p-1}-x_{n+p-2}+\ldots+x_{k+1}-x_{k}|\\
&\leq|x_{n+p}-x_{n+p-1}|+|x_{n+p-1}-x_{n+p-2}|+\ldots+|x_{k+1}-x_{k}|\\
&\leq q^{p-1}|x_{k+1}-x_{k}|+q^{p-2}|x_{k+1}-x_{k}|+\ldots+|x_{k+1}-x_{k}|\\
&=(q^{p-1}+q^{p-2}+\ldots+1)|x_{k+1}-x_{k}|\\
&=\frac{1-q^{p-1}}{1-q}|x_{k+1}-x_{k}|
\end{aligned}
$$
当$p\to\infty$时， $\displaystyle|x^*-x_k|\leq\frac{1}{1-q}|x_{k+1}-x_{k}|$

由上式易得：$\displaystyle|x^*-x_k|\leq\frac{q^k}{1-q}|x_{1}-x_{0}|$

​	 **局部收敛定理：**
$$
\begin{aligned}
&(a)\exist\delta>0,\varphi(x)\in CN(x^*,\delta)\\
&(b)|\varphi^\prime(x)|\leq1
\end{aligned}
$$
满足以上条件也可保证$x=\varphi(x)$局部收敛

**关于改造迭代函数的方法1** ：

​	给定方程$f(x)=0$求其根，最容易想到的方法就是在方程两边同时加上$x$，变为$x=f(x)+x=\varphi(x)$，但是迭代函数并不一定能满足收敛条件，下面介绍一种改造迭代函数的方法：

- 首先确定$f^\prime(x)\in[m,M],0\leq m \leq M$

- 修改方程为：$x=x-\lambda f(x)\Rightarrow \varphi(x)=x-\lambda f(x)$

- 确定$\lambda$的取值
  $$
  \begin{aligned}
  &|\varphi^\prime(x)|=|1-\lambda f^\prime(x)|<1\\
  \Leftrightarrow&\quad -1<1-\lambda f^\prime(x)<1\\
  \Leftrightarrow&\quad 0<\lambda f^\prime(x)<2\\ 
  \Leftrightarrow&\quad 0<\lambda<\frac2M\\
  \end{aligned}
  $$

**关于改造迭代函数的方法2** ：

​	给定迭代方程$x=\varphi(x)$，改造迭代函数$\phi(x)=\varphi(x)+\lambda[\varphi(x)-x]s.t.\phi(x^*)\approx0$，此时近似有：
$$
\lambda=\frac{\varphi^{\prime}(x^*)}{1-\varphi^{\prime}(x^*)}\approx\frac{\varphi^{\prime}(x_k)}{1-\varphi^{\prime}(x_k)}
$$
​	这种方法实际上调节了每次迭代的步长（类似与神经网络中的学习率控制参数更新速度）

#### 2. Aitken迭代法

**关于Picard迭代法的简单改进：**

​	Picard迭代法计算格式简单，但其收敛速度一般较慢，为提高其收敛速度，本节考虑改进 Picard迭代法. 设 $x_{k}$ 为第k次迭代逼近值，迭代函数 $\varphi(x)$ 在方程$x=\varphi(x)$的精确解 $x^{*}$ 的某邻域内连续可微，且其导数值变化不大,记其近似值为$l$，则由Taylor展开式有

$$
\begin{aligned}x^*-\varphi(x_k)&=\varphi(x^*)-\varphi(x_k)\\&=\int_0^1\varphi'(x_k+\theta(x^*-x_k))(x^*-x_k)\mathrm{d}\theta\\&\approx l(x^*-x_k).\end{aligned}
$$

由此得

$$
\begin{aligned}x^*\approx(1-l)^{-1}[\varphi(x_k)-lx_k].\end{aligned}
$$

故得加速迭代格式

$$
\begin{aligned}x_{k+1}=(1-l)^{-1}[\varphi(x_k)-lx_k],\quad k=0,1,\cdots.\end{aligned}
$$
**Aitken迭代法:**

​	上述迭代格式可加快 Picard迭代法的收敛速度，但该方法的缺陷是需要确定参数 $l$， 而这对于某些方程而言是十分困难的.为克服该困难,我们引入如下 Aitken (艾特肯）加速迭代法.记

$$
\begin{aligned}\overline{x}_{k+1}=\varphi(x_{k}),\quad\overline{\overline{x}}_{k+1}=\varphi(\overline{x}_{k+1}),\end{aligned}
$$

则由 Taylor展开定理近似地有

$$
x^{*}-\bar{x}_{k+1}\approx l(x^{*}-x_{k}),\quad x^{*}-\overline{\overline{x}}_{k+1}\approx l(x^{*}-\overline{x}_{k+1}).
$$

由上两式消去未知参数$l$得

$$
\begin{aligned}x^*\approx\overline{\overline{x}}_{k+1}-\frac{(\overline{\overline{x}}_{k+1}-\overline{x}_{k+1})^2}{\overline{\overline{x}}_{k+1}-2\overline{x}_{k+1}+x_k}.\end{aligned}
$$

故得Aitken 加速迭代格式

$$
\begin{aligned}x_{k+1}=\overline{\overline{x}}_{k+1}-\frac{(\overline{\overline{x}}_{k+1}-\overline{x}_{k+1})^2}{\overline{\overline{x}}_{k+1}-2\overline{x}_{k+1}+x_k}\:.\end{aligned}
$$

Aitken迭代无需计算导数值，这是其最大的优势之一，下面给出Aitken迭代法的Python实现：

```python
def f(x):
    return x**3 - 1


import math
c = 1.5
b = 0.0
a = 0.0
i = 1
while(True):
    temp = c
    a = f(c)
    b = f(a)
    c = b - (b - a)**2/(b - 2*a + c)
    if math.fabs(temp-c) < 10e-8:
        break
    print(f'Epoch {i}:{a, b, c}')
    i += 1
```

输出如下：

```python
Epoch 1:(2.375, 12.396484375, 1.4162929745889379)
Epoch 2:(1.8409219520206377, 5.238872775042185, 1.355650441476643)
Epoch 3:(1.4913982755079211, 2.31727067672883, 1.3289487772840105)
Epoch 4:(1.347062884477487, 1.4443512334659498, 1.324804489041044)
Epoch 5:(1.3251735451531022, 1.3271172853522044, 1.3247179939688145)
```

### 三. Newton迭代法（重要）

​	Newton 迭代法是一种求解非线性方程的高效方法，其通过在隔离区间 $[a,b]$ 上不断作曲线 $y=f(x)$ 的切线而获得解的逼近序列.构造该方法的具体步骤如下：在方程$f(x)=0$的解的隔离区间 $[a,b]$ 上选取适当迭代初值$x_0$，过曲线 $y=f(x)$ 的点
$(x_0,f(x_0))$引切线  
$$
\begin{aligned}l_1:\quad&y=f(x_0)+f'(x_0)(x-x_0),\end{aligned}
$$

其与$x$轴相交于点

$$
x_1=x_0-\frac{f(x_0)}{f'(x_0)}
$$

进一步,过曲线 $y=f(x)$ 的点 $(x_1,f(x_1))$ 引切线

$$
l_2:\quad y=f(x_1)+f'(x_1)(x-x_1)
$$

其与$x$轴相交于点

$$
x_2=x_1-\frac{f(x_1)}{f'(x_1)}
$$

如此循环往复，可得一列逼近方程$y=f(x)$ 精确解$x^*$的点
$x_0,x_1,\ldots,x_k,\ldots$，其一般表达式为
$$
\begin{aligned}x_k&=x_{k-1}-\frac{f(x_{k-1})}{f'(x_{k-1})},\quad k=1,2,\cdots.\end{aligned}
$$

该公式所表述的求解方法称为 **Newton 迭代法**或**切线法**

$Example：$应用 Newton 迭代法求方程 $x^3-x-1=0$ 在 $x=1$附近的数值解$x_k$，并使其满足 $|x_k-x_{k-1}|<10^{-8}.$

代码实现如下

```python
def f_(x):
    return 3*(x**2) - 1

def f(x):
    return x**3 -1 - x


a = 1.3
while(True):
    temp = a
    print(a)
    a = a - f(a)/f_(a)
    if math.fabs(temp - a) < 10e-8:
        break
```

输出：

```python
1.3
1.3253071253071254
1.324718280461173
1.3247179572448433 
```

Newton法收敛的充分条件：

设 $f\in\mathbb{C}^2[a,b],$ 若满足以下条件：
$$
\begin{aligned}
&(1)f(a)f(b)<0\\
&(2）\forall x\in[a,b],f^{\prime\prime} (x)>0(<0)f^{\prime}(x)\neq0;\\
&(3)Choose\quad x_0\in[a,b] s.t. f(x_{0})f^{\prime\prime}\left(x_{0}\right)>0;
\end{aligned}
$$
则$\{x_{k}\}$收敛到$f(x)$在$[a,b]$的唯一根。

牛顿法主要有**两个缺点**：**局部收敛，计算量大**

**牛顿法的简化版本**：

- 简易Newton法
  $$
  x_{k+1}=x_k-\frac{f(x_k)}M\quad\quad(k=0,1,2,...)
  $$
  
- 割线法
  $$
  x_{k+1}=x_k-\frac{x_k-x_{k-1}}{f(x_k)-f(x_{k-1})}f(x_k)\quad(k=0,1,2,\cdot\cdot\cdot)
  $$
  
- 牛顿下山法
  $$
  x_{k+1}=x_k-\boldsymbol{\omega}\frac{f(x_k)}{f^{^{\prime}}(x_k)}\quad(k=0,1,2,\cdots)
  $$

  可引入一个下山因子 $\omega(0<\omega\leq1)$使每一步有 $|f(x_{k+1})|<|f(x_k)|$（同样为步长控制，$\omega$为学习率）

P46 2.3 2.5 2.6